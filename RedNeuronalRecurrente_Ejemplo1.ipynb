{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLRdg/IV/2su6rXRQr1A+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mevangelista-alvarado/neural_networks/blob/main/RedNeuronalRecurrente_Ejemplo1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![urc_logo_ext.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "HzFX3WwJNcFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción"
      ],
      "metadata": {
        "id": "327bCwBaNoaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejemplo, construiremos una red neuronal recurrente (RNN) para predecir la siguiente palabra en una secuencia de palabras en un enfoque de procesamiento de lenguaje natural (NLP) con `Numpy`."
      ],
      "metadata": {
        "id": "Xv9D3hH6OXto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementación en Python"
      ],
      "metadata": {
        "id": "vxsusnmVNyuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Importación de Bibliotecas__"
      ],
      "metadata": {
        "id": "qLtU_1zZk0hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos los módulos necesarios"
      ],
      "metadata": {
        "id": "lMYGSaWrOQFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "gX_HZhr8N_dk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Datos de Entrenamiento__"
      ],
      "metadata": {
        "id": "30YY7iJgkx5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos los datos de entrenamiento, que es una cadena de texto."
      ],
      "metadata": {
        "id": "fh10OPSIOSUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de entrenamiento\n",
        "text = \"Hola, ¿cómo estás? Soy una red neuronal recurrente simple. Hago predicción de secuencias de palabras.\""
      ],
      "metadata": {
        "id": "AtYwxFzzOAbB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos todas las palabras de nuestro texto"
      ],
      "metadata": {
        "id": "2qp7X-jUjAuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()"
      ],
      "metadata": {
        "id": "_ZifrcXajBPW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos dos diccionarios de la siguiente manera\n",
        "\n",
        "*   Diccionario 1:  \n",
        "    `{\"index\": \"word\"}`\n",
        "*   Diccionario 1:  \n",
        "    `{\"word\": \"index\"}`\n",
        "\n",
        "que mapean cada palabra única a un índice y viceversa."
      ],
      "metadata": {
        "id": "UiA88-SvjHYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto es útil para convertir palabras en números enteros y viceversa."
      ],
      "metadata": {
        "id": "d3LGi3e3jyYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizacion\n",
        "word_to_idx = {word: idx for idx, word in enumerate(words)}\n",
        "idx_to_word = {idx: word for idx, word in enumerate(words)}"
      ],
      "metadata": {
        "id": "FQSN9hTFiyMR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Preparación de Datos de Entrada y Salida__"
      ],
      "metadata": {
        "id": "kMlbToaAkCt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 3 # Puedes cambir por otro numero, por ejemplo 5.\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(words) - seq_length):\n",
        "    seq_in = words[i:i + seq_length]\n",
        "    seq_out = words[i + seq_length]\n",
        "    X.append([word_to_idx[word] for word in seq_in])\n",
        "    y.append(word_to_idx[seq_out])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "Z-tgmWFQkC3C"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establecemos `seq_length` en `3`, lo que significa que vamos a tomar secuencias de 3 caracteres como entrada y tratar de predecir el siguiente carácter.  \n",
        "\n",
        "Creamos dos listas, `X` e `y`, donde `X` contendrá las secuencias de entrada codificadas como números enteros e `y` contendrá las palabras de destino codificados de la misma manera.\n",
        "\n",
        "Luego, convertimos estas listas en matrices `NumPy` para facilitar el procesamiento."
      ],
      "metadata": {
        "id": "xK-73N-okFng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Creación del Modelo RNN__"
      ],
      "metadata": {
        "id": "eFphjie1kp5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Hiperparámetros_"
      ],
      "metadata": {
        "id": "6tX583kAygiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(words)\n",
        "hidden_size = 32\n",
        "output_size = len(words)\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "uOfZU1pfyi2V"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se definen varios hiperparámetros importantes:\n",
        "* `input_size`:  \n",
        "    La cantidad total de palabras en el vocabulario.\n",
        "* `hidden_size`:  \n",
        "    La dimensión del estado oculto de la RNN.\n",
        "* `output_size`:  \n",
        "    La cantidad total de palabras en el vocabulario (misma que input_size en este caso).\n",
        "* `learning_rate`:\n",
        "    La tasa de aprendizaje utilizada en la actualización de pesos."
      ],
      "metadata": {
        "id": "FU6SkOvkyqP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Inicialización de Pesos y Bias_"
      ],
      "metadata": {
        "id": "0pydwtGYy5K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "Wxh = np.random.randn(hidden_size, input_size)\n",
        "Whh = np.random.randn(hidden_size, hidden_size)\n",
        "Why = np.random.randn(output_size, hidden_size)\n",
        "bh = np.zeros((hidden_size, 1))\n",
        "by = np.zeros((output_size, 1))"
      ],
      "metadata": {
        "id": "wRlIBfloy-Fr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se inicializan los pesos y bias de la RNN de manera aleatoria utilizando `np.random.randn` para crear matrices de pesos y bias inicializados en ceros.\n",
        "\n",
        "* Wxh:  \n",
        "    Matriz de pesos que mapea las entradas (las representaciones de palabras) a los estados ocultos de la RNN en un solo paso de tiempo. Su forma es (hidden_size, input_size).  \n",
        "    \n",
        "    Esta matriz controla cómo las palabras de entrada afectan el estado oculto en el paso de tiempo actual.\n",
        "\n",
        "* `Whh`:  \n",
        "    Matriz de pesos que mapea los estados ocultos anteriores a los estados ocultos actuales en un solo paso de tiempo. Su forma es (hidden_size, hidden_size).\n",
        "    \n",
        "    Esta matriz controla cómo los estados ocultos previos influyen en los estados ocultos actuales, lo que permite que la RNN capture dependencias a lo largo del tiempo.\n",
        "\n",
        "* `Why`:  \n",
        "    Matriz de pesos que mapea los estados ocultos a las salidas de la RNN (las probabilidades de las palabras objetivo) en un solo paso de tiempo. Su forma es (output_size, hidden_size).\n",
        "    \n",
        "    Esta matriz controla cómo los estados ocultos se utilizan para predecir la siguiente palabra.\n",
        "\n",
        "* `bh`:  \n",
        "    Vector de bias para los estados ocultos.\n",
        "    \n",
        "    Es un vector de tamaño (hidden_size, 1) que se agrega a los estados ocultos antes de aplicar la función de activación.\n",
        "\n",
        "* `by`:  \n",
        "    Vector de bias para las salidas (las probabilidades de las palabras objetivo).\n",
        "    \n",
        "    Es un vector de tamaño (output_size, 1) que se agrega a las salidas antes de aplicar la función softmax.\n",
        "\n",
        "Estos parámetros se utilizarán en el proceso de entrenamiento."
      ],
      "metadata": {
        "id": "ASdxjlV-zBKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Funciones de Activación_\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-zIx79stz4TG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se definen dos funciones importantes:\n",
        "* `tanh(x)`:  \n",
        "    La función de activación tangente hiperbólica que se utiliza en la RNN para calcular el estado oculto.\n",
        "* `softmax(x)`:  \n",
        "    La función de activación softmax que se utiliza para calcular las probabilidades de salida."
      ],
      "metadata": {
        "id": "eO-9AcdGz60S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()"
      ],
      "metadata": {
        "id": "xXCUbSh70AOX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Entrenamiento del Modelo__"
      ],
      "metadata": {
        "id": "dQUiQS3Ol5_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se inicia un bucle de entrenamiento que se ejecuta durante 100 épocas."
      ],
      "metadata": {
        "id": "ki95MrIG0Kmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de la RNN\n",
        "for epoch in range(100):\n",
        "    # Inicialización del estado oculto y la pérdida\n",
        "    hprev = np.zeros((hidden_size, 1))\n",
        "    loss = 0\n",
        "\n",
        "    # Iteración sobre los ejemplos de entrenamiento\n",
        "    for i in range(len(X)):\n",
        "        # Inicialización de diccionarios para almacenar variables intermedias\n",
        "        xs, hs, ys, ps = {}, {}, {}, {}\n",
        "        # hs[t] representa el estado oculto en el paso de tiempo t\n",
        "        hs[-1] = np.copy(hprev)\n",
        "\n",
        "        # Iteración sobre el paso de tiempo:\n",
        "        for t in range(seq_length):\n",
        "            # xs[t] es un vector que representa la palabra de entrada en el paso de tiempo t\n",
        "            xs[t] = np.zeros((input_size, 1))\n",
        "            xs[t][X[i][t]] = 1\n",
        "            # Se calcula el nuevo estado oculto hs[t] en función de la entrada actual,\n",
        "            # el estado oculto anterior hs[t-1], y los pesos y bias (Wxh, Whh, bh).\n",
        "            hs[t] = tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t - 1]) + bh)\n",
        "            # Se calcula la salida ys[t] en función del estado oculto hs[t] y\n",
        "            # los pesos y bias (Why, by).\n",
        "            ys[t] = np.dot(Why, hs[t]) + by\n",
        "            # Se calcula la probabilidad de la palabra objetivo ps[t] utilizando\n",
        "            # la función softmax en ys[t].\n",
        "            ps[t] = softmax(ys[t])\n",
        "\n",
        "        # Cálculo de la pérdida (loss)\n",
        "        loss += -np.log(ps[seq_length - 1][y[i], 0])\n",
        "\n",
        "        # Retropropagación\n",
        "        dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "        dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
        "        dhnext = np.zeros_like(hs[0])\n",
        "\n",
        "        # Los gradientes se retropropagan desde el último paso de tiempo hacia el primero.\n",
        "        for t in reversed(range(seq_length)):\n",
        "            dy = np.copy(ps[t])\n",
        "            dy[y[i]] -= 1\n",
        "            dWhy += np.dot(dy, hs[t].T)\n",
        "            dby += dy\n",
        "            dh = np.dot(Why.T, dy) + dhnext\n",
        "            dhraw = (1 - hs[t] * hs[t]) * dh\n",
        "            dbh += dhraw\n",
        "            dWxh += np.dot(dhraw, xs[t].T)\n",
        "            dWhh += np.dot(dhraw, hs[t - 1].T)\n",
        "            dhnext = np.dot(Whh.T, dhraw)\n",
        "\n",
        "        # Recorte de gradientes (gradient clipping)\n",
        "        for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "            np.clip(dparam, -5, 5, out=dparam)\n",
        "\n",
        "        # Actualización de pesos y bias\n",
        "        for param, dparam in zip([Wxh, Whh, Why, bh, by], [dWxh, dWhh, dWhy, dbh, dby]):\n",
        "            param -= learning_rate * dparam\n",
        "\n",
        "    # Impresión de la pérdida (loss)\n",
        "    print(f'Epoch {epoch}: loss = {loss}')"
      ],
      "metadata": {
        "id": "le9fosL8l_AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cada época, se inicializa el estado oculto `hprev` en ceros y la pérdida `loss` en cero.  \n",
        "\n",
        "\n",
        "Luego, se recorre el conjunto de datos de entrenamiento (`X` e `y`) para realizar el proceso de avance y retropropagación en la RNN.  \n",
        "\n",
        "\n",
        "La pérdida se calcula como la negación del logaritmo de la probabilidad de la palabra objetivo en el último paso de tiempo.  \n",
        "\n",
        "\n",
        "Luego, se realiza la retropropagación a través del tiempo para calcular los gradientes de los pesos y bias, y se actualizan los parámetros utilizando el descenso de gradiente.  \n",
        "\n",
        "\n",
        "El modelo aprenderá a predecir el siguiente carácter en una secuencia basándose en los patrones en los datos de entrenamiento.  "
      ],
      "metadata": {
        "id": "JFKVOAFDl8_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Generación de Texto__"
      ],
      "metadata": {
        "id": "A2Fv62f6mIOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se inicia con una secuencia de inicio en la variable `seed_text`, que contiene las primeras palabras que se utilizarán para generar texto."
      ],
      "metadata": {
        "id": "oBOwsfo8mMcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generación de texto\n",
        "# seed_text = [\"Hola,\", \"¿cómo\"]\n",
        "seed_text = [\"Soy\", \"una\", \"red\", \"neuronal\"]\n",
        "h = np.zeros((hidden_size, 1))  # Inicializa el estado oculto h\n",
        "for _ in range(3):\n",
        "    x = np.zeros((input_size, 1))\n",
        "    x[word_to_idx[seed_text[-1]]] = 1\n",
        "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
        "    y = np.dot(Why, h) + by\n",
        "    p = softmax(y)\n",
        "    next_word_idx = np.random.choice(range(output_size), p=p.ravel())\n",
        "    next_word = idx_to_word[next_word_idx]\n",
        "    seed_text.append(next_word)\n",
        "\n",
        "generated_text = ' '.join(seed_text)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "wd321QpXmMi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se inicializa el estado oculto `h` en ceros.\n",
        "\n",
        "Se realiza un bucle para generar texto adicional:\n",
        "* Se convierte la secuencia actual con un 1 en la posición correspondiente a la última palabra de la secuencia.\n",
        "* Se calcula la siguiente palabra utilizando la RNN.\n",
        "* Se agrega la palabra generada a la secuencia actual.\n",
        "\n",
        "Finalmente, se convierte la secuencia generada en una cadena de texto y se imprime.\n"
      ],
      "metadata": {
        "id": "g527at61mUJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código muestra el proceso básico de entrenamiento y generación de texto utilizando una RNN simple.\n",
        "\n",
        "El modelo aprende a predecir la siguiente palabra en función de las secuencias de palabras de entrada y, una vez entrenado, puede generar texto similar a partir de una secuencia de inicio."
      ],
      "metadata": {
        "id": "OqbV9F3G1nI0"
      }
    }
  ]
}